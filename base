#!/usr/bin/python

import scipy.stats as scs
import bs4 as bs
import datetime as dt
import os
import pickle
import requests
import numpy as np
import matplotlib.pyplot as plt
import pandas as pd
import quandl
import csv
import urllib2
import scipy
import scipy.fftpack
import statsmodels.tsa.stattools as ts
import statsmodels as smt
import random
import glob
import statsmodels.api as sm
import datetime as dt
from sklearn.linear_model import LinearRegression, LogisticRegression
from sklearn.ensemble import RandomForestRegressor
from dateutil import parser
from pandas.plotting import register_matplotlib_converters
from pylab import *
from matplotlib import style
# pd.core.common.is_list_like = pd.api.types.is_list_like # necessary in some pandas versions
# import pandas_datareader.data as web

def write_to(df,name,flag):
    try:
        if(flag=="csv"):
            df.to_csv("stock_dfs/" + str(name)+".csv")
        elif(flag=="html"):
            df.to_html(str(name)+"html")
    except ValueError:
        print("No other types supported")

def get_tickers(tickers):
    for ticker in tickers:
        ticker = str(ticker)
        try: 
            print(ticker)
            quandl.ApiConfig.api_key = ""
            df = quandl.get("WIKI/" + ticker, start_date = "2015-12-31", end_date = "2018-12-31")
            write_to(df,str(ticker),"csv")
        except ValueError:
            print("Error")
            print(ticker)

def save_sp500_tickers():
    resp = requests.get('http://en.wikipedia.org/wiki/List_of_S%26P_500_companies')
    soup = bs.BeautifulSoup(resp.text, 'lxml')
    table = soup.find('table', {'class': 'wikitable sortable'})
    tickers = []
    for row in table.findAll('tr')[1:]:
        ticker = row.findAll('td')[1].text
        tickers.append(ticker)
    with open("sp500tickers.pickle", "wb") as f:
        pickle.dump(tickers, f)
    with open("sp500tickers.txt", 'w') as f:
        for item in tickers:
            f.write("%s\n" % item)        
    return(tickers)
    
def read_data(tickers,flag_set_index):
    out = pd.DataFrame()
    for symbol in tickers:
        filename = 'stock_dfs/' + str(symbol) + '.csv'
        df = pd.read_csv(filename)[['Date', 'Adj. Open','Adj. High','Adj. Low','Adj. Close','Adj. Volume']]
        df.columns = ['date','open','high','low','close','volume']
        df['symbol'] = symbol # add a new column which contains the symbol so we can keep multiple symbols in the same dataframe
        df = df.set_index(['date','symbol'])
        out = pd.concat([out,df],axis=0) #stacks on top of previously collected data
    return(out.sort_index())

def view_data(df,flag):
    try:
        if(flag==0):
            print(df.head())
        elif(flag==1):
            print(df.tail())
    except:
        print("No valid flag choice")

def get_features(prices):
    features = pd.DataFrame(index=prices.index)
    features['volume_change_ratio'] = prices.groupby(level='symbol').volume.diff(1) \
                                            / prices.groupby(level='symbol').shift(1).volume
    features['momentum_5_day'] = prices.groupby(level='symbol').close.pct_change(5) 
    features['intraday_chg'] = (prices.groupby(level='symbol').close\
                                .shift(0) - prices.groupby(level='symbol').open\
                                .shift(0))/prices.groupby(level='symbol').open.shift(0)

    features['day_of_week'] = map(parser.parse,features.index.get_level_values('date'))
    features['day_of_week'] = features['day_of_week'].apply( lambda x: x.weekday())
    features['day_of_month'] = map(parser.parse,features.index.get_level_values('date'))
    features['day_of_month'] = features['day_of_month'].apply( lambda x: x.day)
    features.dropna(inplace=True)
    return(features)

def create_outcomes(prices):
    outcomes = pd.DataFrame(index=prices.index)
    # next day's opening change
    outcomes['open_1'] = prices.groupby(level='symbol').open.shift(-1)/prices.groupby(level='symbol').close.shift(0)-1
    # next day's closing change
    func_one_day_ahead = lambda x: x.pct_change(-1)
    outcomes['close_1'] = prices.groupby(level='symbol').close.apply(func_one_day_ahead)
    func_five_day_ahead = lambda x: x.pct_change(-5)
    outcomes['close_5'] = prices.groupby(level='symbol').close.apply(func_five_day_ahead)
    return(outcomes)   

def mach_learn(features,outcomes,mlt):
    y = outcomes.close_5
    X = features

    Xy = X.join(y).dropna()

    X = Xy[X.columns]
    y = Xy[y.name]

    if(mlt == 'linr'):
        model = LinearRegression()
        model.fit(X,y)
        print("Model RSQ: "+ str(model.score(X,y)))
        print("Coefficients: ")
        print(pd.Series(model.coef_,index=X.columns).sort_values(ascending=False))
    elif(mlt == 'rndf'):
        model = RandomForestRegressor(max_features=3)
        model.fit(X,y)
        print("Model Score: "+ str(model.score(X,y)))
        print("Feature Importance: ")
        print(pd.Series(model.feature_importances_,index=X.columns).sort_values(ascending=False))
    else:
        print('No valid choice for classifier')
    
def features_probe(features,flag):
    features.reset_index(inplace=True)
    symbs = list(set(features.symbol))
    df = features[['symbol','volume_change_ratio']]
    if(flag == 'odd'):
        print(df[df.index % 2 != 0])
    elif(flag == 'even'):
        print(df[df.index % 2 == 0])
        
if __name__ == '__main__':
    # tickers = save_sp500_tickers()
    # get_tickers(tickers)

    tickers = ['AAPL','CSCO', 'AMZN']
    prices = read_data(tickers,True)
    df_features = get_features(prices)
    df_outcomes = create_outcomes(prices)
    mach_learn(df_features,df_outcomes,'lin')

